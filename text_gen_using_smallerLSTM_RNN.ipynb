{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled441.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV6Dr7vnSDCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "4103ee98-310e-467d-93d5-71f8814f7776"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7xhLsY9SSHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"/content/yo.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRteMiOKSYE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLpMF8HVSbNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "b9ae658c-7228-4780-8988-b5f7b18f993f"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163824\n",
            "Total Vocab:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0TsugUPSon8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d471f991-b10b-4a30-bd68-ee18e4a3e2f7"
      },
      "source": [
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  163724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Ic3JlTSxEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrtXuY4yS4e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ss-ovxXS8p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ZlU0gBTAyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "d3880c65-1d7b-4360-bc1d-f6474c9c6b3d"
      },
      "source": [
        "model.fit(X, y, epochs=20, batch_size=128, callbacks=callbacks_list)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "163724/163724 [==============================] - 978s 6ms/step - loss: 2.9858\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.98583, saving model to weights-improvement-01-2.9858.hdf5\n",
            "Epoch 2/20\n",
            "163724/163724 [==============================] - 1026s 6ms/step - loss: 2.8085\n",
            "\n",
            "Epoch 00002: loss improved from 2.98583 to 2.80849, saving model to weights-improvement-02-2.8085.hdf5\n",
            "Epoch 3/20\n",
            "163724/163724 [==============================] - 994s 6ms/step - loss: 2.7290\n",
            "\n",
            "Epoch 00003: loss improved from 2.80849 to 2.72903, saving model to weights-improvement-03-2.7290.hdf5\n",
            "Epoch 4/20\n",
            "163724/163724 [==============================] - 991s 6ms/step - loss: 2.6594\n",
            "\n",
            "Epoch 00004: loss improved from 2.72903 to 2.65941, saving model to weights-improvement-04-2.6594.hdf5\n",
            "Epoch 5/20\n",
            "163724/163724 [==============================] - 984s 6ms/step - loss: 2.6022\n",
            "\n",
            "Epoch 00005: loss improved from 2.65941 to 2.60222, saving model to weights-improvement-05-2.6022.hdf5\n",
            "Epoch 6/20\n",
            "163724/163724 [==============================] - 982s 6ms/step - loss: 2.5479\n",
            "\n",
            "Epoch 00006: loss improved from 2.60222 to 2.54792, saving model to weights-improvement-06-2.5479.hdf5\n",
            "Epoch 7/20\n",
            "163724/163724 [==============================] - 981s 6ms/step - loss: 2.4966\n",
            "\n",
            "Epoch 00007: loss improved from 2.54792 to 2.49656, saving model to weights-improvement-07-2.4966.hdf5\n",
            "Epoch 8/20\n",
            "163724/163724 [==============================] - 965s 6ms/step - loss: 2.4527\n",
            "\n",
            "Epoch 00008: loss improved from 2.49656 to 2.45273, saving model to weights-improvement-08-2.4527.hdf5\n",
            "Epoch 9/20\n",
            "163724/163724 [==============================] - 970s 6ms/step - loss: 2.4116\n",
            "\n",
            "Epoch 00009: loss improved from 2.45273 to 2.41163, saving model to weights-improvement-09-2.4116.hdf5\n",
            "Epoch 10/20\n",
            "163724/163724 [==============================] - 979s 6ms/step - loss: 2.3715\n",
            "\n",
            "Epoch 00010: loss improved from 2.41163 to 2.37153, saving model to weights-improvement-10-2.3715.hdf5\n",
            "Epoch 11/20\n",
            "163724/163724 [==============================] - 970s 6ms/step - loss: 2.3350\n",
            "\n",
            "Epoch 00011: loss improved from 2.37153 to 2.33501, saving model to weights-improvement-11-2.3350.hdf5\n",
            "Epoch 12/20\n",
            "163724/163724 [==============================] - 969s 6ms/step - loss: 2.3021\n",
            "\n",
            "Epoch 00012: loss improved from 2.33501 to 2.30209, saving model to weights-improvement-12-2.3021.hdf5\n",
            "Epoch 13/20\n",
            "163724/163724 [==============================] - 978s 6ms/step - loss: 2.2678\n",
            "\n",
            "Epoch 00013: loss improved from 2.30209 to 2.26784, saving model to weights-improvement-13-2.2678.hdf5\n",
            "Epoch 14/20\n",
            "163724/163724 [==============================] - 975s 6ms/step - loss: 2.2360\n",
            "\n",
            "Epoch 00014: loss improved from 2.26784 to 2.23603, saving model to weights-improvement-14-2.2360.hdf5\n",
            "Epoch 15/20\n",
            "163724/163724 [==============================] - 1005s 6ms/step - loss: 2.2064\n",
            "\n",
            "Epoch 00015: loss improved from 2.23603 to 2.20639, saving model to weights-improvement-15-2.2064.hdf5\n",
            "Epoch 16/20\n",
            "163724/163724 [==============================] - 971s 6ms/step - loss: 2.1767\n",
            "\n",
            "Epoch 00016: loss improved from 2.20639 to 2.17673, saving model to weights-improvement-16-2.1767.hdf5\n",
            "Epoch 17/20\n",
            "163724/163724 [==============================] - 970s 6ms/step - loss: 2.1487\n",
            "\n",
            "Epoch 00017: loss improved from 2.17673 to 2.14874, saving model to weights-improvement-17-2.1487.hdf5\n",
            "Epoch 18/20\n",
            "163724/163724 [==============================] - 975s 6ms/step - loss: 2.1229\n",
            "\n",
            "Epoch 00018: loss improved from 2.14874 to 2.12294, saving model to weights-improvement-18-2.1229.hdf5\n",
            "Epoch 19/20\n",
            "163724/163724 [==============================] - 977s 6ms/step - loss: 2.0983\n",
            "\n",
            "Epoch 00019: loss improved from 2.12294 to 2.09830, saving model to weights-improvement-19-2.0983.hdf5\n",
            "Epoch 20/20\n",
            "163724/163724 [==============================] - 982s 6ms/step - loss: 2.0759\n",
            "\n",
            "Epoch 00020: loss improved from 2.09830 to 2.07589, saving model to weights-improvement-20-2.0759.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f81f7a79c18>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VdIe3T3wTO3M",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# load the network weights\n",
        "filename = \"weights-improvement-19-2.0983.hdf5\"\n",
        "model.load_weights(filename)\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fsm_NCRTQOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaHMHbpJTUkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 154
        },
        "outputId": "b7cbc062-ca48-46fc-ced7-e304882da57d"
      },
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" had finished.\n",
            "\n",
            "'as if it wasn't trouble enough hatching the eggs,' said the pigeon;\n",
            "'but i must be o \"\n",
            "o the tart worl ' she said to herself, 'it was a little saree to tee thet io toe tooe to the tare the har hnr the was oo the tooe  the was aot the war oo the tooe tf the care, and she was qotting to tee thtt hnr herd the was oo the tooee th the catee and the war oo the tooe tf the care, and she whit har herd to tee the whrt hnr herd the was oo the tooee th the catee and the war oo the tooe tf the care, and she whit har herd to tee the whrt hnr herd the was oo the tooee th the catee and the war oo the tooe tf the care, and she whit har herd to tee the whrt hnr herd the was oo the tooee th the catee and the war oo the tooe tf the care, and she whit har herd to tee the whrt hnr herd the was oo the tooee th the catee and the war oo the tooe tf the care, and she whit har herd to tee the whrt hnr herd the was oo the tooee th the catee and the war oo the tooe tf the care, and she whit har herd to tee the whrt hnr herd the was oo the tooee th the catee and the war oo the tooe tf the care, and \n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}