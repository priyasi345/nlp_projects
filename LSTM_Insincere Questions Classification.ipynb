{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled293.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMIZo71HSulQsqhZ9v28kd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/priyasi345/nlp_projects/blob/master/LSTM_Insincere%20Questions%20Classification.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BVvdg1c4NYD8",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np \n",
        "import pandas as pd \n",
        "import os\n",
        "import spacy\n",
        "import string\n",
        "import re\n",
        "import numpy as np\n",
        "from spacy.symbols import ORTH\n",
        "from collections import Counter\n",
        "from pathlib import Path\n",
        "from sklearn.model_selection import train_test_split\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ECGKDlAlNcy0",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "7604c38e-0a1f-44b7-ec5d-a48a828d0cd6"
      },
      "source": [
        "\n",
        "PATH = Path(\"/content/\")\n",
        "list(PATH.iterdir())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[PosixPath('/content/.config'),\n",
              " PosixPath('/content/train.csv'),\n",
              " PosixPath('/content/test.csv (1).zip'),\n",
              " PosixPath('/content/sample_submission (2).csv'),\n",
              " PosixPath('/content/sample_data')]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9wVdd2nQSubt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "9c5dfa40-2052-402f-8d82-d27297c5833a"
      },
      "source": [
        "!unzip '/content/test.csv (1).zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/test.csv (1).zip\n",
            "  inflating: test.csv                \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Iup6PkIJsv2D",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b38ce0f8-1379-4267-ef49-a6bf3be56711"
      },
      "source": [
        "!unzip '/content/trainn.csv.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "unzip:  cannot find or open /content/trainn.csv.zip, /content/trainn.csv.zip.zip or /content/trainn.csv.zip.ZIP.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tkIPNfAKNggO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train = pd.read_csv(PATH/\"train.csv\")\n",
        "df_test = pd.read_csv(PATH/\"test.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Mo1ssL3YNjjq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 195
        },
        "outputId": "598ff106-95d3-4342-c8c4-81592eeb8265"
      },
      "source": [
        "df_train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>qid</th>\n",
              "      <th>question_text</th>\n",
              "      <th>target</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>00002165364db923c7e6</td>\n",
              "      <td>How did Quebec nationalists see their province...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>000032939017120e6e44</td>\n",
              "      <td>Do you have an adopted dog, how would you enco...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0000412ca6e4628ce2cf</td>\n",
              "      <td>Why does velocity affect time? Does velocity a...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>000042bf85aa498cd78e</td>\n",
              "      <td>How did Otto von Guericke used the Magdeburg h...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0000455dfa3e01eae3af</td>\n",
              "      <td>Can I convert montra helicon D to a mountain b...</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                    qid  ... target\n",
              "0  00002165364db923c7e6  ...    0.0\n",
              "1  000032939017120e6e44  ...    0.0\n",
              "2  0000412ca6e4628ce2cf  ...    0.0\n",
              "3  000042bf85aa498cd78e  ...    0.0\n",
              "4  0000455dfa3e01eae3af  ...    0.0\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XnLF4W2pNl1k",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_train['question_text'] = df_train['question_text'].astype(str)\n",
        "df_train['qid'] = df_train['qid'].astype(str)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6kSkC-RUNxLg",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "re_br = re.compile(r'<\\s*br\\s*/?>', re.IGNORECASE)\n",
        "def sub_br(x): return re_br.sub(\"\\n\", x)\n",
        "\n",
        "my_tok = spacy.load('en')\n",
        "def spacy_tok(x): return [tok.text for tok in my_tok.tokenizer(sub_br(x))]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KdoDbUPPNzyd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "outputId": "12af3a94-4e4d-4cb1-88e2-54152f54e4da"
      },
      "source": [
        "text = df_train['question_text'][0]\n",
        "spacy_tok(text)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['How',\n",
              " 'did',\n",
              " 'Quebec',\n",
              " 'nationalists',\n",
              " 'see',\n",
              " 'their',\n",
              " 'province',\n",
              " 'as',\n",
              " 'a',\n",
              " 'nation',\n",
              " 'in',\n",
              " 'the',\n",
              " '1960s',\n",
              " '?']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "crOd17FdN0Q1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "counts = Counter()\n",
        "for q in df_train['question_text']:\n",
        "    counts.update(spacy_tok(q))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r_ZvayZYN2uG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for word in list(counts):\n",
        "    if counts[word] < 5:\n",
        "        del counts[word]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4gyARKaHN4tw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "vocab2index = {\"\":0, \"UNK\":1}\n",
        "words = [\"\", \"UNK\"]\n",
        "for word in counts:\n",
        "    vocab2index[word] = len(words)\n",
        "    words.append(word)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ARuDu688N6j7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "def encode_sentence(row, vocab2index, N=100, padding_start=True):\n",
        "    words = spacy_tok(row)\n",
        "    enc = np.zeros(N, dtype=np.int32)\n",
        "    enc1 = np.array([vocab2index.get(word, vocab2index[\"UNK\"]) for word in words])\n",
        "    l = min(N, len(enc1))\n",
        "    if padding_start:\n",
        "        enc[:l] = enc1[:l]\n",
        "    else:\n",
        "        enc[N-l:] = enc1[:l]\n",
        "    return enc, l"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vGa2nnhIN88i",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "f9c5bf34-7f7c-4600-d4d1-3e8c6031c325"
      },
      "source": [
        "encode_sentence(df_train['question_text'][0], vocab2index, N=100, padding_start=False)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([ 0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,  0,\n",
              "         0,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15],\n",
              "       dtype=int32), 14)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h8ufjpPjN-z7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "x_train_len = np.array([len(q.split()) for q in df_train['question_text']])\n",
        "x_test_len = np.array([len(q.split()) for q in df_test['question_text']])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KH4lVmVjOA-g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fb47fc11-6106-4fcd-da97-8b78950e28f7"
      },
      "source": [
        "x_train_len.max(), x_test_len.max()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(66, 87)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eXN8PckVOF4K",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "a9ff3611-f817-46f2-d58c-aec85a46a793"
      },
      "source": [
        "N_train = np.percentile(x_train_len, 99)\n",
        "N_test = np.percentile(x_test_len, 99)\n",
        "\n",
        "N_train, N_test"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(39.0, 39.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-dOpUXm6OGLT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "N=40\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_8bmz7KROJzX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train, valid = train_test_split(df_train, test_size=0.2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PfcVUzYuONR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class QuoraDataset(Dataset):\n",
        "    def __init__(self, df, vocab2index, is_test=False, N=40, padding_start=True):\n",
        "        self.question = [encode_sentence(q, vocab2index, N, padding_start) for q in df['question_text']]\n",
        "        self.is_test = is_test\n",
        "        if self.is_test:\n",
        "            self.y = None\n",
        "        else:\n",
        "            self.y = list(df[\"target\"])\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.y)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        x, s = self.question[idx]\n",
        "        \n",
        "        if self.is_test:\n",
        "            return x\n",
        "        else:\n",
        "            y = self.y[idx]\n",
        "            return x, s, y"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1DWePgNSOQHr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "train_ds = QuoraDataset(train, vocab2index, N=40, padding_start=False)\n",
        "valid_ds = QuoraDataset(valid, vocab2index, N=40, padding_start=False)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZuXrU1UdOSyo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "batch_size = 1000\n",
        "train_dl = DataLoader(train_ds, batch_size=batch_size, shuffle=True)\n",
        "valid_dl = DataLoader(valid_ds, batch_size=batch_size)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mswzM4IZOUqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x,s,y = next(iter(train_dl))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fHUI60yeOZxz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "a2b9a20c-2f8d-4752-9a48-05f9af23cb85"
      },
      "source": [
        "train_ds[0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(array([    0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "            0,     0,     0,     0,     0,     2,    33, 14790,    59,\n",
              "        14197,  4070,    17,    15], dtype=int32), 8, 0.0)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UnjvpKoJ_FK8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "597c0cd3-ac60-4fe6-d4a0-09293318e2fe"
      },
      "source": [
        "!unzip '/content/1835_3176_compressed_glove.6B.100d.txt.zip'"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  /content/1835_3176_compressed_glove.6B.100d.txt.zip\n",
            "  inflating: glove.6B.100d.txt       \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CLJ_rYTzOaQ-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def loadGloveModel(gloveFile=\"glove.6B.100d.txt\"):\n",
        "    \"\"\" Loads word vectors into a dictionary.\"\"\"\n",
        "    f = open(gloveFile,'r')\n",
        "    word_vecs = {}\n",
        "    for line in f:\n",
        "        splitLine = line.split()\n",
        "        word = splitLine[0]\n",
        "        word_vecs[word] = np.array([float(val) for val in splitLine[1:]])\n",
        "    return word_vecs\n",
        "word_vecs = loadGloveModel()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QaiSZfV9OcZR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def random_word_vector(D=90):\n",
        "    \"\"\"Create arandom word vector\n",
        "    \n",
        "    0.25 is chosen so the unknown vectors have (approximately) same variance \n",
        "    as pre-trained ones\n",
        "    \"\"\"\n",
        "    return np.random.uniform(-0.25,0.25,D)\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2dodO53snZwW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def create_embedding_matrix(word_vecs, vocab2index, words, D=90):\n",
        "    \"\"\"Creates embedding matrix from word vectors. \"\"\"\n",
        "    V = len(words)\n",
        "    W = np.zeros((V, D), dtype=\"float32\")\n",
        "    W[0] = np.zeros(D, dtype='float32')\n",
        "    i = 1\n",
        "    for i in range(1, V):\n",
        "        if words[i] in word_vecs:\n",
        "            W[i] = word_vecs[words[i]]\n",
        "        else:\n",
        "            W[i] = random_word_vector()\n",
        "    return W"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m9a5RnB-OesU",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 296
        },
        "outputId": "23f23a9a-6242-41e8-eac1-e9abb392d863"
      },
      "source": [
        "embedding_matrix = create_embedding_matrix(word_vecs, vocab2index, words)\n",
        "embedding_matrix.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-34-0e8df6fd8353>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0membedding_matrix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_embedding_matrix\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword_vecs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvocab2index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-33-73095577cc78>\u001b[0m in \u001b[0;36mcreate_embedding_matrix\u001b[0;34m(word_vecs, vocab2index, words, D)\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mV\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mword_vecs\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m             \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mword_vecs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m             \u001b[0mW\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrandom_word_vector\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not broadcast input array from shape (100) into shape (90)"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qw9OeH41OgrE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "class GRUBiModel(torch.nn.Module) :\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix) :\n",
        "        super(GRUBiModel,self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.embeddings.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "        self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True,\n",
        "                            dropout=0.3, bidirectional=True)\n",
        "        self.linear = nn.Linear(2*hidden_dim, 1)\n",
        "        \n",
        "    def forward(self, x, s):\n",
        "        s, sort_index = torch.sort(s, 0,descending=True)\n",
        "        s = s.numpy().tolist()\n",
        "        x = x[sort_index]\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "        x_pack = pack_padded_sequence(x, s, batch_first=True)\n",
        "        out_pack, ht = self.gru(x_pack)\n",
        "        h = torch.cat((ht[-2,:,:], ht[-1,:,:]), dim = 1)\n",
        "        return self.linear(h)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WcqjJ0iNOjfM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Define the first NN \n",
        "class LSTM_GRU(nn.Module):\n",
        "    def __init__(self, vocab_size, embedding_dim, hidden_dim, embedding_matrix):\n",
        "        super(LSTM_GRU, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "\n",
        "        self.embeddings = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
        "        self.embeddings.weight.data.copy_(torch.from_numpy(embedding_matrix))\n",
        "        self.embeddings.weight.requires_grad = False ## freeze embeddings\n",
        "        self.dropout = nn.Dropout(0.5)\n",
        "\n",
        "#         self.gru = nn.GRU(embedding_dim, hidden_dim, num_layers=2, batch_first=True,\n",
        "#                             dropout=0.3)\n",
        "        \n",
        "        \n",
        "        self.embedding_dropout = nn.Dropout2d(0.01)\n",
        "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        self.gru = nn.GRU(embedding_dim*2, hidden_dim, bidirectional=True, batch_first=True)\n",
        "        \n",
        "        self.linear = nn.Linear(2*hidden_dim, 1)\n",
        "#         self.linear = nn.Linear(1024+features.shape[1], 16)\n",
        "#         self.relu = nn.ELU()\n",
        "#         self.dropout = nn.Dropout(0.01)\n",
        "        \n",
        "    def forward(self, x, s):\n",
        "        s, sort_index = torch.sort(s, 0,descending=True)\n",
        "        s = s.numpy().tolist()\n",
        "        x = x[sort_index]\n",
        "        x = self.embeddings(x)\n",
        "        x = self.dropout(x)\n",
        "#         x_pack = pack_padded_sequence(x, s, batch_first=True)\n",
        "        lstm_pack, (ht, ct) = self.lstm(x)\n",
        "        out_pack, ht = self.gru(lstm_pack)\n",
        "        h = torch.cat((ht[-2,:,:], ht[-1,:,:]), dim = 1)\n",
        "        return self.linear(h)\n",
        "        "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kS3oe7P1Oowt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_epocs(model, epochs=10, lr=0.001):\n",
        "    parameters = filter(lambda p: p.requires_grad, model.parameters())\n",
        "    optimizer = torch.optim.Adam(parameters, lr=lr)\n",
        "    for i in range(epochs):\n",
        "        model.train()\n",
        "        sum_loss = 0.0\n",
        "        total = 0\n",
        "        for x, s, y in train_dl:\n",
        "            x = x.long()\n",
        "            y = y.float()\n",
        "            y_pred = model(x, s)\n",
        "            optimizer.zero_grad()\n",
        "            loss = F.binary_cross_entropy_with_logits(y_pred, y.unsqueeze(1))\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            sum_loss += loss.item()*y.shape[0]\n",
        "            total += y.shape[0]\n",
        "        val_loss, val_acc = val_metrics(model, valid_dl)\n",
        "        if i % 5 == 1:\n",
        "            print(\"train loss %.3f val loss %.3f and val accuracy %.3f\" % (sum_loss/total, val_loss, val_acc))\n",
        "\n",
        "def val_metrics(model, valid_dl):\n",
        "    model.eval()\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    sum_loss = 0.0\n",
        "    for x, s, y in valid_dl:\n",
        "        x = x.long()\n",
        "        y = y.float().unsqueeze(1)\n",
        "        y_hat = model(x, s)\n",
        "        loss = F.binary_cross_entropy_with_logits(y_hat, y)\n",
        "        y_pred = y_hat > 0\n",
        "        correct += (y_pred.float() == y).float().sum()\n",
        "        total += y.shape[0]\n",
        "        sum_loss += loss.item()*y.shape[0]\n",
        "    return sum_loss/total, correct/total"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2j8m9SsOtyJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "82380f73-685d-4c96-fdaa-410e828116b8"
      },
      "source": [
        "\n",
        "vocab_size = len(words)\n",
        "print(vocab_size)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "57673\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t0SIXQlIOuPd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 162
        },
        "outputId": "e53556da-5bfc-44b0-d681-243b07208542"
      },
      "source": [
        "model = LSTM_GRU(vocab_size, 300, 300, embedding_matrix)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-53-897db0a4c1b5>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTM_GRU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvocab_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m300\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding_matrix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'embedding_matrix' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i_F4SfkvOxAV",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "%%time\n",
        "train_epocs(model, epochs=15, lr=0.01)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bTybfS1NOzMm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def save_model(m, p): \n",
        "    torch.save(m.state_dict(), p)\n",
        "    \n",
        "def load_model(m, p): \n",
        "    m.load_state_dict(torch.load(p))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdjMOBmnO1jG",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "p1 = \"./models/model-96.pth\"\n",
        "save_model(model, p1)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kzrAphg7O4I3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model1 = LSTMModel(vocab_size, 50, 50)\n",
        "model_path = \"./models/model-96.pth\"\n",
        "load_model(model1, model_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X-ra73U_O6i2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "test_ds = QuoraDataset(df_test, vocab2index, is_test=True, N=40, padding_start=False)\n",
        "test_dl = DataLoader(test_ds, batch_size=1000)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LdPqP_jEO8fl",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_submission = pd.read_csv(PATH/\"sample_submission.csv\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lq9H-eeQO-WO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "preds=[]\n",
        "for x in test_dl:\n",
        "    x = x[0].long()\n",
        "    out = model(x)\n",
        "    pred = (out > 0.0).long()\n",
        "    preds.append(pred.numpy())"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXnllkh-PAJe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_submission['prediction'] = np.vstack(preds)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rw7WdgTlPCdb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_submission.head()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "F5uG4NGePEQN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df_submission.to_csv('submission.csv', index=False)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}