# -*- coding: utf-8 -*-
"""ml_trees(4).ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1wtWaRGwfsTr8y7KRJq5WBNQatcFCLH8D
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
import statsmodels.api as sm
from sklearn.tree import DecisionTreeRegressor
from sklearn.ensemble import RandomForestRegressor

data = pd.read_csv('/content/Metro-Interstate-Traffic-Volume-Encoded.csv')

data.head()

X = data.drop('traffic_volume',axis=1)
Y = data['traffic_volume']

from sklearn.model_selection import train_test_split

xtrain,xtest,ytrain,ytest=train_test_split(X,Y,test_size=0.25,random_state=0)

DT = DecisionTreeRegressor()

DT.fit(xtrain,ytrain)

pred = DT.predict(xtest)

import sklearn.metrics as metrics

print('R Squared : ',metrics.r2_score(ytest,pred))

print('Mean Absolute Error : ',metrics.mean_absolute_error(ytest,pred))

print('Mean Squared Error : ',metrics.mean_squared_error(ytest,pred))

print('Root Mean Squared Error : ',np.sqrt(metrics.mean_squared_error(ytest,pred)))

"""Grid Search for Hyper Parameter"""

from sklearn.model_selection import GridSearchCV

Dt = DecisionTreeRegressor()

parameter ={'max_depth':np.arange(1,10)}
GS=GridSearchCV(DT,parameter,cv=3)
GS.fit(X,Y)

GS.best_params_

DT = DecisionTreeRegressor(max_depth=7)

DT.fit(xtrain,ytrain)

pred = DT.predict(xtest)

"""Evaluation Metrics"""

print('R Squared : ',metrics.r2_score(ytest,pred))

print('Mean Absolute Error : ',metrics.mean_absolute_error(ytest,pred))

print('Mean Squared Error : ',metrics.mean_squared_error(ytest,pred))

print('Root Mean Squared Error : ',np.sqrt(metrics.mean_squared_error(ytest,pred)))

print('Bias Error')
print('Actual value :',np.mean(ytest))
print('Predicted value :',np.mean(pred))

print('Variance Error')
print('Actual value :',np.var(ytest,ddof=1))
print('Predicted value :',np.var(pred,ddof=1))

RT = RandomForestRegressor()

RT.fit(xtrain,ytrain)

pred = RT.predict(xtest)

print('R Squared : ',metrics.r2_score(ytest,pred))

print('Mean Absolute Error : ',metrics.mean_absolute_error(ytest,pred))

"""Grid Search for Hyper Parameter"""

RT = RandomForestRegressor()

parameter ={'max_depth':np.arange(1,10),'n_estimators':np.arange(1,15)}
GS=GridSearchCV(RT,parameter,cv=3)
GS.fit(X,Y)

GS.best_params_

RT = RandomForestRegressor(n_estimators=9,max_depth=7)

RT.fit(xtrain,ytrain)

pred = RT.predict(xtest)

print('R Squared : ',metrics.r2_score(ytest,pred))

print('Mean Absolute Error : ',metrics.mean_absolute_error(ytest,pred))

print('Mean Squared Error : ',metrics.mean_squared_error(ytest,pred))

print('Root Mean Squared Error : ',np.sqrt(metrics.mean_squared_error(ytest,pred)))

print('Bias Error')
print('Actual value :',np.mean(ytest))
print('Predicted value :',np.mean(pred))

print('Variance Error')
print('Actual value :',np.var(ytest,ddof=1))
print('Predicted value :',np.var(pred,ddof=1))

"""Random forest has given a better R squared score than the Decision tree.
But both the bias error as well as variance error has increased a little.

Overall comparing all the models Decision tree is the better model. All the scores MAE,MSE,RMSE,R^2 scores are better when compared with other model. Since it as less chance of overfitting when compared with other models it can be used for prediction.The variance error can further reduced by using Ensembling Techniques.
"""