{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "text_gen_Text Generation With larger LSTM Recurrent Neural network",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "WV6Dr7vnSDCr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f145b278-5a5f-4092-ac6c-828e090171bc"
      },
      "source": [
        "import numpy\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.callbacks import ModelCheckpoint\n",
        "from keras.utils import np_utils"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7xhLsY9SSHa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# load ascii text and covert to lowercase\n",
        "filename = \"/content/yo.txt\"\n",
        "raw_text = open(filename, 'r', encoding='utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRteMiOKSYE1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# create mapping of unique chars to integers\n",
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c, i) for i, c in enumerate(chars))"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vLpMF8HVSbNn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "582746f7-70d6-4fcb-a955-4a7957df8b5e"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print (\"Total Characters: \", n_chars)\n",
        "print (\"Total Vocab: \", n_vocab)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  163824\n",
            "Total Vocab:  59\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i0TsugUPSon8",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "83af38ec-a3b5-4062-f1ab-21f06da6a2ce"
      },
      "source": [
        "\n",
        "# prepare the dataset of input to output pairs encoded as integers\n",
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "\tseq_in = raw_text[i:i + seq_length]\n",
        "\tseq_out = raw_text[i + seq_length]\n",
        "\tdataX.append([char_to_int[char] for char in seq_in])\n",
        "\tdataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print (\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  163724\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-Ic3JlTSxEf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# reshape X to be [samples, time steps, features]\n",
        "X = numpy.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "# normalize\n",
        "X = X / float(n_vocab)\n",
        "# one hot encode the output variable\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrtXuY4yS4e9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define the LSTM model\n",
        "model = Sequential()\n",
        "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation='softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_ss-ovxXS8p1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "# define the checkpoint\n",
        "filepath=\"weights-improvement-{epoch:02d}-{loss:.4f}-bigger.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w2ZlU0gBTAyg",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 706
        },
        "outputId": "78a55971-0ef5-4d79-9fa8-6cb2652c9b55"
      },
      "source": [
        "model.fit(X, y, epochs=10, batch_size=64, callbacks=callbacks_list)"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "163724/163724 [==============================] - 1267s 8ms/step - loss: 2.9418\n",
            "\n",
            "Epoch 00001: loss improved from inf to 2.94176, saving model to weights-improvement-01-2.9418-bigger.hdf5\n",
            "Epoch 2/10\n",
            "163724/163724 [==============================] - 1262s 8ms/step - loss: 2.7530\n",
            "\n",
            "Epoch 00002: loss improved from 2.94176 to 2.75301, saving model to weights-improvement-02-2.7530-bigger.hdf5\n",
            "Epoch 3/10\n",
            "163724/163724 [==============================] - 1291s 8ms/step - loss: 2.6651\n",
            "\n",
            "Epoch 00003: loss improved from 2.75301 to 2.66513, saving model to weights-improvement-03-2.6651-bigger.hdf5\n",
            "Epoch 4/10\n",
            "163724/163724 [==============================] - 1283s 8ms/step - loss: 2.5942\n",
            "\n",
            "Epoch 00004: loss improved from 2.66513 to 2.59423, saving model to weights-improvement-04-2.5942-bigger.hdf5\n",
            "Epoch 5/10\n",
            "163724/163724 [==============================] - 1279s 8ms/step - loss: 2.5280\n",
            "\n",
            "Epoch 00005: loss improved from 2.59423 to 2.52800, saving model to weights-improvement-05-2.5280-bigger.hdf5\n",
            "Epoch 6/10\n",
            "163724/163724 [==============================] - 1280s 8ms/step - loss: 2.4670\n",
            "\n",
            "Epoch 00006: loss improved from 2.52800 to 2.46703, saving model to weights-improvement-06-2.4670-bigger.hdf5\n",
            "Epoch 7/10\n",
            "163724/163724 [==============================] - 1287s 8ms/step - loss: 2.4106\n",
            "\n",
            "Epoch 00007: loss improved from 2.46703 to 2.41058, saving model to weights-improvement-07-2.4106-bigger.hdf5\n",
            "Epoch 8/10\n",
            "163724/163724 [==============================] - 1285s 8ms/step - loss: 2.3603\n",
            "\n",
            "Epoch 00008: loss improved from 2.41058 to 2.36035, saving model to weights-improvement-08-2.3603-bigger.hdf5\n",
            "Epoch 9/10\n",
            "163724/163724 [==============================] - 1315s 8ms/step - loss: 2.3153\n",
            "\n",
            "Epoch 00009: loss improved from 2.36035 to 2.31533, saving model to weights-improvement-09-2.3153-bigger.hdf5\n",
            "Epoch 10/10\n",
            "163724/163724 [==============================] - 1310s 8ms/step - loss: 2.2722\n",
            "\n",
            "Epoch 00010: loss improved from 2.31533 to 2.27221, saving model to weights-improvement-10-2.2722-bigger.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.callbacks.History at 0x7f8efed88940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3Fsm_NCRTQOn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "int_to_char = dict((i, c) for i, c in enumerate(chars))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jaHMHbpJTUkb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 171
        },
        "outputId": "443bcd2f-8cf1-4557-ef25-d64af07956f0"
      },
      "source": [
        "import sys\n",
        "# pick a random seed\n",
        "start = numpy.random.randint(0, len(dataX)-1)\n",
        "pattern = dataX[start]\n",
        "print (\"Seed:\")\n",
        "print (\"\\\"\", ''.join([int_to_char[value] for value in pattern]), \"\\\"\")\n",
        "# generate characters\n",
        "for i in range(1000):\n",
        "\tx = numpy.reshape(pattern, (1, len(pattern), 1))\n",
        "\tx = x / float(n_vocab)\n",
        "\tprediction = model.predict(x, verbose=0)\n",
        "\tindex = numpy.argmax(prediction)\n",
        "\tresult = int_to_char[index]\n",
        "\tseq_in = [int_to_char[value] for value in pattern]\n",
        "\tsys.stdout.write(result)\n",
        "\tpattern.append(index)\n",
        "\tpattern = pattern[1:len(pattern)]\n",
        "print (\"\\nDone.\")"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Seed:\n",
            "\" only hear whispers\n",
            "now and then; such as, 'sure, i don't like it, yer honour, at all, at\n",
            "all!' 'do a \"\n",
            " mottee toine to thi wout, \n",
            "the mocs turtle soine oo the toike \n",
            "the had tot oo the tooee the had dou to tee tooee the had dou ana the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had dou to tee tooe of the sooee th the gour of the garee thr sas the tooee th the tooed the had do\n",
            "Done.\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}